<!doctype html>

<!--
Copyright (c) Meta Platforms, Inc. and affiliates.

This source code is licensed under the MIT license found in the
LICENSE file in the root directory of this source tree.
-->

<head>
    <style>
        .boxed {
            border: 1px solid black;
        }

        .styleform label {
            float: left;
            margin: 5px 10px 5px 10px;
        }

        .styleform input {
            margin: 5px 10px 5px 10px;
        }

        /* this gives space for the label on the left */
        .styleform .clear {
            clear: both;
        }

        /* prevent elements from stacking weirdly */
    </style>
    <title>Test Ultra low latency with WebCodecs ENCODER (by Jordi Cenzano)</title>
</head>

<body>
    <h1>MOQT Test Ultra low latency with Webcodecs: ENCODER</h1>
    <h2><a href="https://datatracker.ietf.org/doc/draft-ietf-moq-transport/">MOQT Version</a>: <label id="moqtVersion">-</label>, <a href="https://datatracker.ietf.org/doc/draft-cenzano-moq-media-interop/">MediaPackager Version</a>: <label id="moqMediaPackagerVersion">-</label></h2>
    <div class="boxed">
        <div class="styleform">
            <form>
                <h2>Data needed</h2>
                <div class="clear"></div>
                <label id="wtDestData">MOQT WT Relay:<input id="wtServerUrl" type="text"
                        value="https://localhost:4433/moq" size="64"></label>
                <div class="clear"></div>
                <label>Namespace:<input id="namespace" type="text" value="vc"></label><label>Use character '/' to separate tuples</label>
                <div class="clear"></div>
                <label>Track name prefix (audio0, video0 will be added):<input id="trackName" type="text" value="202112241726"></label><label>Old
                    Track name:</label><input id="oldTrackName" type="text" value="-" readonly>
                <div class="clear"></div>
                <label>Full track names (based on namespace and track name):<input id="fullTrackNames" type="text" value="-" size="64" readonly></label>
                <div class="clear"></div>
                <label>Max inflight audio requests:<input id="maxInflightAudioRequests" type="text" value="60"></label>
                <div class="clear"></div>
                <label>Max inflight video requests:<input id="maxInflightVideoRequests" type="text" value="39"></label>
                <div class="clear"></div>
                <label>AuthInfo (for all tracks, shared with subscribers):<input id="authInfo" type="text" value="secret"></label>
                <div class="clear"></div>
                <label>MOQ video packager:<select id="moqVideoQuicMapping"></select></label>  
                <label>MOQ audio packager:<select id="moqAudioQuicMapping"></select></label>  
                <div class="clear"></div>
                <h3>Video encoding params (h264)</h3>
                <label>Input sources: <select id="videoSources"></select></label>      
                (If you select "Screen" and a window with small refresh rate it can affect A LOT the time to 1st frame and time to loss recovery )          
                <div class="clear"></div>
                <label>Resolution @ fps: <select id="videoEncodingOptions"></select></label>
                <label>KeyFrame every (frames):<input id="videoEncodingKeyFrameEvery" type="text" value="60"
                        size="5"></label>
                <label>Bitrate (bps): <input id="videoEncodingBitrateBps" type="text" value="750000" size="8"></label>
                <div class="clear"></div>
                <label>Activate latency tracker (overlays data on video): <input type="checkbox" id="activateLatencyTracker"></label>
                <div class="clear"></div>
                <h3>Audio encoding params</h3>
                <label>Input sources: <select id="audioSources"></select></label>                
                <div class="clear"></div>
                <label>Codec: <select id="audioCodecOptions"></select></label>                
                <div class="clear"></div>
                <label>Bitrate (bps): <select id="audioEncodingBitrateBpsOptions"></select></label>
                <div class="clear"></div>
                <button id="btnStart" type="button">Start</button>
                <button id="btnStop" type="button" disabled>Stop</button>
            </form>
        </div>
    </div>
    <div class="boxed">
        <video height="50%" id="vPreview" autoplay muted></video>
    </div>
    <div class="boxed">
        <h2>Capture(uncompressed domain)</h2>
        <div class="styleform">
            <form>
                <label>First audio TS(ms): <input id="firstAts" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>First video TS(ms): <input id="firstVts" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>V-A start diff(ms): <input id="VAdiff" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>First comp audio TS(ms): <input id="firstCompAts" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>First comp video TS(ms): <input id="firstCompVts" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>V-A comp start diff(ms): <input id="VACompdiff" type="text" value="" readonly></label>
                <div class="clear"></div>

            </form>
        </div>
    </div>
    <div class="boxed">
        <h2>Encoder output (chunks)</h2>
        <div class="styleform">
            <form>
                <label>Current audio TS(ms):<input id="encodedAudioTs" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>Current comp audio TS(ms):<input id="encodedAudioCompensatedTs" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>Encoding audio latency (ms):<input id="encodedAudioLatencyMs" type="text" value="" readonly></label>
                <div class="clear"></div>                
                <label>Current video TS(ms):<input id="encodedVideoTs" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>Current comp video TS(ms):<input id="encodedVideoCompensatedTs" type="text" value="" readonly></label>
                <div class="clear"></div>
                <label>Encoding video latency (ms):<input id="encodedVideoLatencyMs" type="text" value="" readonly></label>
                <div class="clear"></div>                
                
                <label>Current V-A TS(ms):<input id="encodedVADelayCompensatedTS" type="text" value="" readonly></label>
                <div class="clear"></div>
                                
            </form>        
        </div>
    </div>
    <div class="boxed">
        <h2>Muxer sender</h2>
        <div>
            <h3>Inflight</h3>
            <div class="styleform">
                <form>
                    <label>Inflight audio requests:<input id="uploadStatsAudioInflight" type="text" value=""
                            readonly></label>
                    <div class="clear"></div>
                    <label>Inflight video requests:<input id="uploadStatsVideoInflight" type="text" value=""
                            readonly></label>
                    <div class="clear"></div>
                </form>
            </div>
        </div>
    </div>
    <div class="boxed">
        <h2>Dropped data (frames / chunks):</h2>
        <div class="styleform">
            <form>
                <label>Total dropped audio chunks: <input id="totalAudioChunksDropped" type="text" value=""
                        readonly></label>
                <div class="clear"></div>
                <label>Total dropped video chunks: <input id="totalVideoChunksDropped" type="text" value=""
                        readonly></label>
                <div class="clear"></div>
            </form>
        </div>
        <ol id="droppedFrames"></ol>
    </div>
</body>
<script type="module">
    import { TimeBufferChecker } from "../utils/time_buffer_checker.js"
    import { MOQ_MAPPING_SUBGROUP_PER_GROUP, MOQ_MAPPING_OBJECT_PER_DATAGRAM, MOQ_CURRENT_VERSION, getFullTrackName } from "../utils/moqt.js"
    import { getBinaryFile } from "../utils/utils.js"
    import { OverlayEncoder } from "../overlay_processor/overlay_encoder.js"
    import { GetVideoCodecStringFromProfileLevel } from "../utils/media/avc_decoder_configuration_record_parser.js"
    import { MI_PACKAGER_VERSION, MIgetTrackName } from "../packager/mi_packager.js"

    // Main vars
    let VERBOSE = false;
    let IS_LOCALHOST = false;

    // Current TS generated by capture
    let currentAudioTs = undefined;
    let currentVideoTs = undefined;
    let videoOffsetTS = undefined;
    let audioOffsetTS = undefined;

    // Video encoder config
    const videoEncoderConfig = {
        encoderConfig: {
            codec: 'avc1.42001e', // Baseline = 66, level 30 (see: https://en.wikipedia.org/wiki/Advanced_Video_Coding)
            width: 320,
            height: 180,
            bitrate: 1_000_000, // 1 Mbps
            framerate: 30,
            latencyMode: 'realtime', // Sends 1 chunk per frame
        },
        encoderMaxQueueSize: 2,
        keyframeEvery: 60,
    };

    // Audio encoder config
    const audioEncoderConfig = {
        encoderConfig: {
            codec: 'opus', // To fill later
            sampleRate: 48000, // To fill later
            numberOfChannels: 1, // To fill later
            bitrate: 32000,
        },
        encoderMaxQueueSize: 10,
    };

    // To keep some stats
    let dropChunksTotals = {};
    let statsHelper = {};

    function returnMax(varName, val) {
        let ret = val;
        if (!(varName in statsHelper)) {
            statsHelper[varName] = val;
        } else {
            if (statsHelper[varName] > val) {
                ret = statsHelper[varName];
            } else {
                statsHelper[varName] = val;
            }
        }
        return ret;
    }

    // To keep track of the frame generation time between frame & chunk

    const audioTimeChecker = new TimeBufferChecker("audio");
    const videoTimeChecker = new TimeBufferChecker("video");

    // Used in case we use latency tracker
    const overlayEncoder = new OverlayEncoder();

    const muxerSenderConfig = {
        urlHostPort: '',
        urlPath: '',

        keepAlivesEveryMs: 5000,

        certificateHash: null,

        moqTracks: {
            "audio": {
                namespace: ["vc"],
                name: "audio0",
                maxInFlightRequests: 100,
                isHipri: true,
                authInfo: "secret",
                moqMapping: MOQ_MAPPING_SUBGROUP_PER_GROUP,
            },
            "video": {
                namespace: ["vc"],
                name: "video0",
                maxInFlightRequests: 50,
                isHipri: false,
                authInfo: "secret",
                moqMapping: MOQ_MAPPING_SUBGROUP_PER_GROUP,
            }
        },
    }

    // Current workers
    let vStreamWorker = null;
    let aStreamWorker = null;
    let vEncoderWorker = null;
    let aEncoderWorker = null;
    let muxerSenderWorker = null;

    // Read & parse QS data
    const queryString = window.location.search;
    console.log("Read querystring: " + queryString);
    const qsParams = new URLSearchParams(queryString);

    function createWorkers() {
        // Create a new workers for video / audio frames capture
        vStreamWorker = new Worker("../capture/v_capture.js", { type: "module" });
        aStreamWorker = new Worker("../capture/a_capture.js", { type: "module" });

        // Create a new workers for video / audio frames encode
        vEncoderWorker = new Worker("../encode/v_encoder.js", { type: "module" });
        aEncoderWorker = new Worker("../encode/a_encoder.js", { type: "module" });

        // Create send worker
        muxerSenderWorker = new Worker("../sender/moq_sender.js", { type: "module" });
    }

    function clearUI() {
        document.getElementById('uploadStatsAudioInflight').value = "0";
        document.getElementById('uploadStatsVideoInflight').value = "0";

        document.getElementById('firstVts').value = "";
        document.getElementById('firstAts').value = "";
        document.getElementById('VAdiff').value = "";

        document.getElementById('firstCompVts').value = "";
        document.getElementById('firstCompAts').value = "";
        document.getElementById('VACompdiff').value = "";

        document.getElementById('droppedFrames').innerHTML = '';

        statsHelper = {};
        dropChunksTotals = {};
    }

    // To update track names
    namespace.addEventListener("input", function (e) {
        updateFullTrackNameUI();
    });
    trackName.addEventListener("input", function (e) {
        updateFullTrackNameUI();
    });

    function numToStrWithPad(d, length) {
        let r = d.toString();
        while (r.length < length) {
            r = "0" + r;
        }
        return r;
    }

    async function initUI() {
        initVersions();
        initMOQMappingModesUI();
        initStreamIDUI();
        initFromQS();
        initEncodingOptionsUI();
        initAudioCodecOptionsUI();
        initAudioBitrateOptionsUI(document.getElementById('audioCodecOptions').options[document.getElementById('audioCodecOptions').selectedIndex].data.codec);
        await populateVideoSourcesUI();
        await populateAudioSourcesUI();

        // Init preview
        const currentVideoDeviceIdIndex = document.getElementById('videoSources').selectedIndex;
        let currentVideoDeviceId = ""
        if (currentVideoDeviceIdIndex > 0) {
            currentVideoDeviceId = document.getElementById("videoSources").options[currentVideoDeviceIdIndex].value;
        }

        const currentAudioDeviceIdIndex = document.getElementById('audioSources').selectedIndex;
        let currentAudioDeviceId = ""
        if (currentVideoDeviceIdIndex > 0) {
            currentAudioDeviceId = document.getElementById("audioSources").options[currentAudioDeviceIdIndex].value;
        }

        const currentVideoEncodingIndex = document.getElementById('videoEncodingOptions').selectedIndex < 0 ? 0 : document.getElementById('videoEncodingOptions').selectedIndex;        
        const currentVideoEncodingOptions = document.getElementById("videoEncodingOptions").options[currentVideoEncodingIndex].data; 
        
        restartPreviewUI(currentVideoDeviceId, currentAudioDeviceId, currentVideoEncodingOptions.w, currentVideoEncodingOptions.h);
    }

    function isSelectedVideoSourceScreen() {
        const currentVideoDeviceIdIndex = document.getElementById('videoSources').selectedIndex;
        if (currentVideoDeviceIdIndex > 0 && document.getElementById("videoSources").options[currentVideoDeviceIdIndex].value == "screen") {
            return true;
        }
        return false;
    }

    function updatePreviewVideoSettingsUI(newWidth, newHeight) {               
        if (document.getElementById('vPreview').srcObject == undefined && document.getElementById('vPreview').srcObject == null) {
            console.error("Preview NOT active yet, we can NOT update video settings"); 
            return;           
        }

        enableUI("processingUpdate");

        const videoConstraints = { height: {min: newHeight, ideal: newHeight}, width: {min: newWidth, ideal: newWidth} };
        const mediaStream = document.getElementById('vPreview').srcObject;
        // Update video async
        const videoTracks = mediaStream.getVideoTracks();
        if (videoTracks.length > 0) {
            videoTracks[0].applyConstraints(videoConstraints)
            .then(() => {
                
                // Set the resolution of preview to encoder resolution
                document.getElementById('vPreview').width = newWidth;
                document.getElementById('vPreview').height = newHeight;

                console.info(`Updated video preview. New settings: ${JSON.stringify(videoTracks[0].getSettings())}`);
            })
            .catch((err) => {
                console.error(`Updating video preview. Err: ${JSON.stringify(err)}`);
            })
            .finally(() => {                
                enableUI("readyToPublish");
            });
        }
    }

    function getMedia(screen, constraints) {
        if (screen) {
            return navigator.mediaDevices.getDisplayMedia(constraints);
        } else {
            return navigator.mediaDevices.getUserMedia(constraints);
        }
    }

    function refreshEnableAudioSourceUI() {
        if (isSelectedVideoSourceScreen()) {
            document.getElementById('audioSources').disabled = true;
        } else {
            document.getElementById('audioSources').disabled = true;
        }
    }

    function getAudioTrackSettings() {
        let ret = undefined

        // Assuming 1 track
        document.getElementById('vPreview').srcObject.getTracks().forEach(function(track) {
            if (track.kind == 'audio') {
                ret = track.getSettings();
            }
        });

        return ret;
    }

    function restartPreviewUI(newVideoDeviceId, newAudioDeviceId, newWidth, newHeight) {
        enableUI("processingUpdate");

        // Remove old stream
        if (document.getElementById('vPreview').srcObject != undefined && document.getElementById('vPreview').srcObject != null) {
            const mediaStream = document.getElementById('vPreview').srcObject;
            const videoTracks = mediaStream.getVideoTracks();
            videoTracks.forEach(function(vTrack) {
                vTrack.stop();
            });
            const audioTracks = mediaStream.getAudioTracks();
            audioTracks.forEach(function(aTrack) {
                aTrack.stop();
            });
            document.getElementById('vPreview').srcObject = null;
        }

        const shareScreen = (newVideoDeviceId === 'screen');
        const constraints = { };
        const videoConstraints = { };
        const audioConstraints = { };
        if (shareScreen) {
            constraints.audio = true;
        } else {
            if (newVideoDeviceId != "") {
                videoConstraints.deviceId = { exact: newVideoDeviceId };
            }
            if (newAudioDeviceId != "") {
                audioConstraints.deviceId = { exact: newAudioDeviceId };
            }
        }
        refreshEnableAudioSourceUI();

        if (newHeight > 0) {
            videoConstraints.height = {ideal: newHeight};
        }
        if (newWidth > 0) {
            videoConstraints.width = {ideal: newWidth};
        }

        constraints.video = videoConstraints;
        constraints.audio = audioConstraints;
                
        // Start new stream
        getMedia(shareScreen, constraints)
        .then(mediaStream => {                    
            // Connect the stream to the preview video element.
            document.getElementById('vPreview').srcObject = mediaStream;      
            
            return mediaStream;
        })
        .then(mediaStream => {
            let videoNumTracks = 0;
            let audioNumTracks = 0;
            document.getElementById('vPreview').srcObject.getTracks().forEach(function(track) {
                if (track.kind == 'video') {
                    console.info(`Started preview: video: ${newVideoDeviceId} - ${newWidth}x${newHeight} From track: ${JSON.stringify(track.getSettings())}`);
                    videoNumTracks++;
                }
                else if (track.kind == 'audio') {
                    console.info(`Started preview: Audio: ${newAudioDeviceId} - From track: ${JSON.stringify(track.getSettings())}`);
                    audioNumTracks++
                }
            });
            if (videoNumTracks != 1 || audioNumTracks != 1) {
                throw new Error(`"We need just 1 video track and 1 audio track for this to work we got: videoTracks: ${videoNumTracks} and audioTracks: ${audioNumTracks}`);
            }
        })
        .catch(err => {
            const msg = `Started video preview. Err: ${err}`
            console.error(msg);
            alert(msg);
        })
        .finally(() => {
            enableUI("readyToPublish");
        });
    }

    function initFromQS() {
        const qsHost = qsParams.get('host')
        if (qsHost != undefined) {
            document.getElementById("wtServerUrl").value = qsHost;
        }
        const verbose_logging = qsParams.get('verbose')
        if (verbose_logging != undefined && verbose_logging === "1") {
            VERBOSE = true
        }
        const local = qsParams.get('local')
        if (local != undefined) {
            IS_LOCALHOST = true
        }
    }

    function updateEncodingAudioLatencyUI(latencyMs) {
        if (latencyMs != undefined) {
            document.getElementById("encodedAudioLatencyMs").value = latencyMs;
        }
    }

    function updateEncodingVideoLatencyUI(latencyMs) {
        if (latencyMs != undefined) {
            document.getElementById("encodedVideoLatencyMs").value = latencyMs;
        }
    }

    function updateEncodedAudioTSUI(audioTS, compensatedAudioTS) {
        if (audioTS != undefined) {
            document.getElementById("encodedAudioTs").value = (audioTS / 1000.0).toFixed(0);
        }
        if (compensatedAudioTS != undefined) {
            document.getElementById("encodedAudioCompensatedTs").value = (compensatedAudioTS / 1000.0).toFixed(0);
        }
        document.getElementById("encodedVADelayCompensatedTS").value = parseInt(document.getElementById("encodedVideoCompensatedTs").value) - parseInt(document.getElementById("encodedAudioCompensatedTs").value);
    }

    function updateEncodedVideoTSUI(videoTS, compensatedVideoTS) {
        if (videoTS != undefined) {
            document.getElementById("encodedVideoTs").value = (videoTS / 1000.0).toFixed(0);
        }
        if (compensatedVideoTS != undefined) {
            document.getElementById("encodedVideoCompensatedTs").value = (compensatedVideoTS / 1000.0).toFixed(0);
        }
        document.getElementById("encodedVADelayCompensatedTS").value = parseInt(document.getElementById("encodedVideoCompensatedTs").value) - parseInt(document.getElementById("encodedAudioCompensatedTs").value);
    }

    function initAudioBitrateOptionsUI(selectedCodec) {
        // Remove old elements
        document.getElementById("audioEncodingBitrateBpsOptions").length = 0;
        const op = document.getElementById("audioEncodingBitrateBpsOptions");
        let isSelected = true;
        if (selectedCodec == "opus") {
            addAudioCodecBitrateOptionUI(op, "32000", 32000, isSelected);
            isSelected = false;
        }
        // AAC supported 96000, 128000, 160000, 192000
        addAudioCodecBitrateOptionUI(op, "96000", 96000, isSelected);
        isSelected = false;
        addAudioCodecBitrateOptionUI(op, "128000", 128000);
        addAudioCodecBitrateOptionUI(op, "160000", 160000);
        addAudioCodecBitrateOptionUI(op, "192000", 192000);
    }

    function addAudioCodecBitrateOptionUI(optionsElement, desc, bitrateBps, isSelected) {
        const o = document.createElement("option")
        o.text = desc
        o.data = {bitrate: bitrateBps}
        if (isSelected) {
            o.selected = true
        }
        optionsElement.options.add(o, 1);
    }

    function initAudioCodecOptionsUI() {
        const op = document.getElementById("audioCodecOptions");
        addAudioCodecOptionUI(op, "Opus", "opus", true);
        addAudioCodecOptionUI(op, "AAC-LC", "mp4a.40.02");
    }

    function initEncodingOptionsUI() {
        const op = document.getElementById("videoEncodingOptions");

        addVideoEncodingOptionUI(op, 320, 180, 15, 12); // 1.2
        addVideoEncodingOptionUI(op, 320, 180, 30, 13); // 1.3
        addVideoEncodingOptionUI(op, 854, 480, 15, 30); // 3
        addVideoEncodingOptionUI(op, 854, 480, 30, 31, true); // 3.1
        addVideoEncodingOptionUI(op, 1280, 720, 15, 31); // 3.1
        addVideoEncodingOptionUI(op, 1280, 720, 30, 31); // 3.1
        addVideoEncodingOptionUI(op, 1920, 1080, 15, 40); // 4
        addVideoEncodingOptionUI(op, 1920, 1080, 30, 40); // 4
    }

    function addVideoEncodingOptionUI(optionsElement, width, height, fps, level, isSelected) {
        const o = document.createElement("option")
        o.text = `${width}x${height}@${fps}`
        o.data = {w: width, h: height, fps: fps, level: level}
        if (isSelected) {
            o.selected = true
        }
        optionsElement.options.add(o, 1);
    }

    function addAudioCodecOptionUI(optionsElement, codecDesc, codecStr, isSelected) {
        const o = document.createElement("option")
        o.text = codecDesc
        o.data = {codec: codecStr}
        if (isSelected) {
            o.selected = true
        }
        optionsElement.options.add(o, 1);
    }

    function updateFullTrackNameUI() {
        const audioFullTrackName = `${getFullTrackName(document.getElementById("namespace").value.split("/"), MIgetTrackName(document.getElementById("trackName").value, true))}`
        const videoFullTrackName = `${getFullTrackName(document.getElementById("namespace").value.split("/"), MIgetTrackName(document.getElementById("trackName").value, false))}`

        document.getElementById("fullTrackNames").value = `${audioFullTrackName}, ${videoFullTrackName}`;
    }

    function initVersions() {
        document.getElementById("moqtVersion").innerHTML = "0x" + MOQ_CURRENT_VERSION.toString(16);
        document.getElementById("moqMediaPackagerVersion").innerHTML = MI_PACKAGER_VERSION;
    }

    function initMOQMappingModesUI(selectElement) {
        initMOQMappingModeUI(document.getElementById('moqVideoQuicMapping'), MOQ_MAPPING_SUBGROUP_PER_GROUP, "video");
        initMOQMappingModeUI(document.getElementById('moqAudioQuicMapping'), MOQ_MAPPING_SUBGROUP_PER_GROUP, "audio");
    }

    function initMOQMappingModeUI(selectElement, moqMappingSelected, mediaType) {
        // Multi object streams (track per stream)
        const optionObjStream = document.createElement('option');
        optionObjStream.value = MOQ_MAPPING_SUBGROUP_PER_GROUP;
        if (moqMappingSelected == MOQ_MAPPING_SUBGROUP_PER_GROUP || moqMappingSelected == undefined) {
            optionObjStream.selected = true;        
        }
        if (mediaType === "video") {
            optionObjStream.appendChild(document.createTextNode("Subgroup per GOP (AKA: GOP per stream)"));
            selectElement.appendChild(optionObjStream);
        } else if (mediaType === "audio") {
            optionObjStream.appendChild(document.createTextNode("Subgroup per frame"));
            selectElement.appendChild(optionObjStream);

            // This protection is because usually IFrames are bigger than a datagram, and allowing to use datagram in video would mean dropping almost all Iframes
            // Stream per datagram
            const optionObjTrack = document.createElement('option');
            optionObjTrack.value = MOQ_MAPPING_OBJECT_PER_DATAGRAM;
            if (moqMappingSelected == MOQ_MAPPING_OBJECT_PER_DATAGRAM) {
                optionObjStream.selected = true;        
            }
            optionObjTrack.appendChild(document.createTextNode("Object per datagram (AKA: Frame per datagram)"));
            selectElement.appendChild(optionObjTrack);
        }
    }

    function initStreamIDUI() {
        const d = new Date();
        const sStr = d.getUTCFullYear().toString() + numToStrWithPad(d.getUTCMonth() + 1, 2) + numToStrWithPad(d.getUTCDate(), 2) + numToStrWithPad(d.getUTCHours(), 2) + numToStrWithPad(d.getUTCMinutes(), 2) + numToStrWithPad(d.getUTCSeconds(), 2);
        document.getElementById("trackName").value = sStr;

        updateFullTrackNameUI();
    }

    function addMediaSource(select, deviceId, label, count, isVideo) {
        const option = document.createElement('option');
        option.value = deviceId;
        if (count === 1) option.selected = true;
        const textNode = document.createTextNode(label);
        option.appendChild(textNode);
        select.appendChild(option);
        const mediaType = (isVideo) ? "Video" : "Audio";
        console.log(`${mediaType} input device added: ${label}(${option.value})`);
    }
    
    async function populateVideoSourcesUI() {
        const select = document.getElementById('videoSources');
        select.innerHTML = '';
        let count = 0;
        // This requires HTTPS or should be served from localhost
        await navigator.mediaDevices
            .enumerateDevices()
            .then(devices => {
                devices.forEach(mediaDevice => {
                    if (mediaDevice.kind === 'videoinput') {
                        if (mediaDevice.deviceId != "") {
                            count++;
                            const label = mediaDevice.label || `Camera ${count}`;
                            addMediaSource(select, mediaDevice.deviceId, label, count, true);
                        }
                    }
                })
            }).catch(err => {
                console.error(`Showing video sources. Err: ${err.name}-${err.message}`);
            });

        addMediaSource(select, 'screen', 'Screen', ++count, true);
    }

    async function populateAudioSourcesUI() {
        const select = document.getElementById('audioSources');
        select.innerHTML = '';
        let count = 0;
        // This does NOT work if you run chrome locally (test mode)
        await navigator.mediaDevices
            .enumerateDevices()
            .then(devices => {
                devices.forEach(mediaDevice => {
                    if (mediaDevice.kind === 'audioinput') {
                        if (mediaDevice.deviceId != "") {
                            count++;
                            const label = mediaDevice.label || `Microphone ${count}`;
                            addMediaSource(select, mediaDevice.deviceId, label, count, false);
                        }
                    }
                })
            }).catch(err => {
                console.error(`Showing audio sources. Err: ${err.name}-${err.message}`);
            });
    }

    function onVideoSourceChanged(newVideoDeviceId) {
        // Get selected audio device
        const audioSourceSelectedIndex = document.getElementById('audioSources').selectedIndex;
        let selectedAudioSourceDeviceId = '';
        if (audioSourceSelectedIndex >= 0) {
            selectedAudioSourceDeviceId = document.getElementById('audioSources').options[audioSourceSelectedIndex].value;
        }

        // Get new selected video device
        const videoOptionsSelectedElementData = document.getElementById('videoEncodingOptions').options[document.getElementById('videoEncodingOptions').selectedIndex].data;

        // Restart preview with new selection
        restartPreviewUI(newVideoDeviceId, selectedAudioSourceDeviceId, videoOptionsSelectedElementData.w, videoOptionsSelectedElementData.h);
    }

    function onAudioSourceChanged(newAudioDeviceId) {
        // Get selected video device
        const videoSourceSelectedIndex = document.getElementById('videoSources').selectedIndex;
        let selectedVideoSourceDeviceId = '';
        if (videoSourceSelectedIndex >= 0) {
            selectedVideoSourceDeviceId = document.getElementById('videoSources').options[videoSourceSelectedIndex].value;
        }        
        const videoOptionsSelectedElementData = document.getElementById('videoEncodingOptions').options[document.getElementById('videoEncodingOptions').selectedIndex].data;

        // Restart preview with new selection
        restartPreviewUI(selectedVideoSourceDeviceId, newAudioDeviceId, videoOptionsSelectedElementData.w, videoOptionsSelectedElementData.h);
    }

    function onVideoEncodingsSettingsChanged(newData) {        
        const videoOptionsSelectedElementData = document.getElementById('videoEncodingOptions').options[document.getElementById('videoEncodingOptions').selectedIndex].data;
        
        updatePreviewVideoSettingsUI(newData.w, newData.h);
    }

    function onAudioCodecChanged(newData) {
        initAudioBitrateOptionsUI(newData.codec);
    }

    function enableUI(mode) {
        if ( mode == "readyToPublish") {
            document.getElementById("btnStart").disabled = false
            document.getElementById("btnStop").disabled = true
            document.getElementById("videoEncodingOptions").disabled = false
            document.getElementById("videoSources").disabled = false
            document.getElementById("audioSources").disabled = isSelectedVideoSourceScreen();
        } else if (mode == "publishing") {
            document.getElementById("btnStart").disabled = true
            document.getElementById("btnStop").disabled = false
            document.getElementById("videoEncodingOptions").disabled = true
            document.getElementById("videoSources").disabled = true
            document.getElementById("audioSources").disabled = true
        } else if (mode == "processingUpdate") {
            // Processing preview update
            document.getElementById("btnStart").disabled = true
            document.getElementById("btnStop").disabled = true
            document.getElementById("videoEncodingOptions").disabled = true
            document.getElementById("videoSources").disabled = true
            document.getElementById("audioSources").disabled = true
        } else {
            console.error(`enableUI unknown mode ${mode}`);
        }
    }

    function stop() {
        enableUI("readyToPublish");
        
        document.getElementById("oldTrackName").value = document.getElementById("trackName").value;
        initStreamIDUI();

        const stopMsg = { type: "stop" };
        aStreamWorker.postMessage(stopMsg);
        vStreamWorker.postMessage(stopMsg);

        vEncoderWorker.postMessage(stopMsg);
        aEncoderWorker.postMessage(stopMsg);

        muxerSenderWorker.postMessage(stopMsg);

        audioTimeChecker.Clear();
        videoTimeChecker.Clear();
    }

    function processWorkerMessage(e) {
        // LOGGING
        if (e.data.type === "debug") {
            if (VERBOSE) {
                // logging debug
                console.debug(e.data.data);
            }            
        } else if (e.data.type === "info") {
            // logging info
            console.log(e.data.data);
        } else if (e.data.type === "error") {
            // logging error
            console.error(e.data.data);
        } else if (e.data.type === "warning") {
            // logging warning
            console.warn(e.data.data);

            // ENCODING
        } else if (e.data.type === "vframe") {
            const vFrame = e.data.data;
            let estimatedDuration = -1;
            if (currentVideoTs == undefined) {
                if (audioOffsetTS == undefined) {
                    // Start video at 0
                    videoOffsetTS = -vFrame.timestamp; // Comp video starts 0
                } else {
                    // Adjust video offset to last audio seen (most probable case since audio startsup faster)
                    videoOffsetTS = -vFrame.timestamp + currentAudioTs + audioOffsetTS; // Comp video starts last audio seen
                }
                updateFirstTS("video", vFrame.timestamp, vFrame.timestamp + videoOffsetTS);
            } else {
                estimatedDuration = vFrame.timestamp - currentVideoTs;
            }
            currentVideoTs = vFrame.timestamp;
            videoTimeChecker.AddItem({ ts: currentVideoTs, compensatedTs: currentVideoTs + videoOffsetTS, estimatedDuration: estimatedDuration, clkms: e.data.clkms });
            
             // Modify pixels
            let vNewFrame = vFrame
            if (document.getElementById('activateLatencyTracker').checked) {
                vNewFrame = overlayEncoder.Encode(vFrame, e.data.clkms)
                if (VERBOSE) {
                    console.debug(`[OVERLAY] Added overlay to frame ts ${vNewFrame.timestamp}, clk: ${e.data.clkms}`)
                }
            }
            
            // Encode video frame
            vEncoderWorker.postMessage({ type: "vframe", vframe: vNewFrame }, [ vNewFrame ]);
        } else if (e.data.type === "aframe") {
            const aFrame = e.data.data;
            let estimatedDuration = -1;
            if (currentAudioTs == undefined) {
                if (videoOffsetTS == undefined) {
                    // Start audio at 0
                    audioOffsetTS = -aFrame.timestamp; // Comp audio starts 0
                } else {
                    // Adjust audio offset to last video seen
                    audioOffsetTS = -aFrame.timestamp + currentVideoTs + videoOffsetTS; // Comp audio starts last video seen
                }
                updateFirstTS("audio", aFrame.timestamp, aFrame.timestamp + audioOffsetTS);
            } else {
                estimatedDuration = aFrame.timestamp - currentAudioTs;
            }
            currentAudioTs = aFrame.timestamp;
            audioTimeChecker.AddItem({ ts: currentAudioTs, compensatedTs: currentAudioTs + audioOffsetTS, estimatedDuration: estimatedDuration, clkms: e.data.clkms });
            // Encode audio frame
            aEncoderWorker.postMessage({ type: "aframe", aframe: aFrame });

            // DROPPED
        } else if (e.data.type === "dropped") {
            updateDroppedFrame(e.data.data);

            // CHUNKS
        } else if (e.data.type === "vchunk") {
            const chunk = e.data.chunk;
            const metadata = e.data.metadata;
            const seqId = e.data.seqId;
            const itemTsClk = videoTimeChecker.GetItemByTs(chunk.timestamp);
            const timebase = e.data.timebase;
            if (!itemTsClk.valid) {
                console.warn(`Not found clock time <-> TS for that video frame, this should not happen.  ts: ${chunk.timestamp}, id:${seqId}`);
            } else {
                updateEncodedVideoTSUI(chunk.timestamp, itemTsClk.compensatedTs);          
                updateEncodingVideoLatencyUI(Date.now()  - itemTsClk.clkms);
            }
            muxerSenderWorker.postMessage({ type: "video", firstFrameClkms: itemTsClk.clkms, compensatedTs: itemTsClk.compensatedTs, estimatedDuration: itemTsClk.estimatedDuration, seqId: seqId, chunk: chunk, metadata, timebase });
        } else if (e.data.type === "achunk") {
            const chunk = e.data.chunk;
            const metadata = e.data.metadata;
            const seqId = e.data.seqId;            
            const timebase = e.data.timebase;
            const sampleFreq = e.data.sampleFreq;
            const numChannels = e.data.numChannels;
            const codec = e.data.codec;
            const itemTsClk = audioTimeChecker.GetItemByTs(chunk.timestamp);
            if (!itemTsClk.valid) {
                console.info(`Not found clock time <-> TS for audio frame, this could happen. ts: ${chunk.timestamp}, id:${seqId}`);
            } else {
                updateEncodedAudioTSUI(chunk.timestamp, itemTsClk.compensatedTs);
                updateEncodingAudioLatencyUI(Date.now()  - itemTsClk.clkms);                
            }
            muxerSenderWorker.postMessage({ type: "audio", firstFrameClkms: itemTsClk.clkms, compensatedTs: itemTsClk.compensatedTs, seqId: seqId, chunk: chunk, metadata: metadata, timebase, sampleFreq, numChannels, codec});
            // CHUNKS STATS
        } else if (e.data.type === "sendstats") {
            updateUploadStats(currentAudioTs, currentVideoTs, e.data.inFlightReq);

            // UNKNOWN
        } else {
            console.error("unknown message: " + e.data);
        }
    }

    function updateUploadStats(currentAudioTs, currentVideoTs, inFlightReq) {
        document.getElementById('uploadStatsAudioInflight').value = `${inFlightReq["audio"]} (${returnMax('inFlightAudioReqNum', inFlightReq["audio"])})`;
        document.getElementById('uploadStatsVideoInflight').value = `${inFlightReq["video"]} (${returnMax('inFlightVideoReqNum', inFlightReq["video"])})`;
    }

    function updateDroppedFrame(droppedFrameData) {
        const list = document.getElementById('droppedFrames');

        const clkms = droppedFrameData.clkms;
        const ts = droppedFrameData.ts;
        const seqId = droppedFrameData.seqId;
        const msg = droppedFrameData.msg;
        const mediaType = droppedFrameData.mediaType;

        if (seqId >= 0) {
            // Is a chunk
            if (!(mediaType in dropChunksTotals)) {
                dropChunksTotals[mediaType] = 1;
            } else {
                dropChunksTotals[mediaType]++;
            }
            if (mediaType == "video") {
                document.getElementById('totalVideoChunksDropped').value = dropChunksTotals[mediaType]
            } else if (mediaType == "audio") {
                document.getElementById('totalAudioChunksDropped').value = dropChunksTotals[mediaType]
            }
        }

        const str = new Date(clkms).toISOString() + " (" + seqId + ")(" + ts + ") " + msg;

        const entry = document.createElement('li');
        entry.appendChild(document.createTextNode(str));
        list.appendChild(entry);
    }

    function updateFirstTS(type, ts, compensatedTs) {
        const tsms = (ts / 1000).toFixed(3);
        const compensatedTsms = (compensatedTs / 1000).toFixed(3);

        if (type === "video") {
            document.getElementById('firstVts').value = tsms;
            document.getElementById('firstCompVts').value = compensatedTsms;
        } else if (type === "audio") {
            document.getElementById('firstAts').value = tsms;
            document.getElementById('firstCompAts').value = compensatedTsms;
        }
        const diffms = document.getElementById('firstVts').value - document.getElementById('firstAts').value
        if (Number.isFinite(diffms / 1000)) {
            document.getElementById('VAdiff').value = (diffms / 1000).toFixed(3);
        }
        const diffCompms = document.getElementById('firstCompVts').value - document.getElementById('firstCompAts').value
        if (Number.isFinite(diffCompms)) {
            document.getElementById('VACompdiff').value = diffCompms.toFixed(3);
        }
    }

    async function start() {
        currentAudioTs = undefined;
        currentVideoTs = undefined;
        videoOffsetTS = undefined;
        audioOffsetTS = undefined;

        enableUI("publishing");

        clearUI();

        createWorkers();
        const videoOptionsSelectedElementData = document.getElementById('videoEncodingOptions').options[document.getElementById('videoEncodingOptions').selectedIndex].data;
        // Load video encoding settings
        videoEncoderConfig.encoderConfig.width = videoOptionsSelectedElementData.w;
        videoEncoderConfig.encoderConfig.height = videoOptionsSelectedElementData.h;
        videoEncoderConfig.encoderConfig.framerate = videoOptionsSelectedElementData.fps;
        videoEncoderConfig.encoderConfig.codec = GetVideoCodecStringFromProfileLevel("avc1", 66, videoOptionsSelectedElementData.level);
        videoEncoderConfig.encoderConfig.bitrate = parseInt(document.getElementById('videoEncodingBitrateBps').value);
        videoEncoderConfig.keyframeEvery = parseInt(document.getElementById('videoEncodingKeyFrameEvery').value);

        // Load audio encoding settings
        const audioOptionsSelectedElementData = document.getElementById('audioCodecOptions').options[document.getElementById('audioCodecOptions').selectedIndex].data;
        audioEncoderConfig.encoderConfig.codec = audioOptionsSelectedElementData.codec;
        if (audioEncoderConfig.encoderConfig.codec != "opus") {
            audioEncoderConfig.encoderConfig.aac = { format: "aac" }
        } else {
            audioEncoderConfig.encoderConfig.opus = { // See https://www.w3.org/TR/webcodecs-opus-codec-registration/
                frameDuration: 10000 // In ns. Lower latency than default = 20000
            }
        }
        const sourceAudioSetting = getAudioTrackSettings();
        audioEncoderConfig.encoderConfig.sampleRate = sourceAudioSetting.sampleRate; // Get from source
        audioEncoderConfig.encoderConfig.numberOfChannels = sourceAudioSetting.channelCount; // Get from source
        const audioBitrate = document.getElementById('audioEncodingBitrateBpsOptions').options[document.getElementById('audioEncodingBitrateBpsOptions').selectedIndex].data.bitrate;
        audioEncoderConfig.encoderConfig.bitrate = audioBitrate;

        // Get a MediaStream from preview
        if (document.getElementById('vPreview').srcObject == undefined || document.getElementById('vPreview').srcObject == null) {
            console.error("Preview is not set, we can not start a publish session");
            return;
        }

        const mediaStream = document.getElementById('vPreview').srcObject;
        if (mediaStream.getVideoTracks().length <= 0) {
            console.error("Publish session can not be started without video tracks in preview");
            return;
        }
        if (mediaStream.getAudioTracks().length <= 0) {
            console.error("Publish session can not be started without audio tracks in preview");
            return;
        }
        
        // Print messages from the worker in the console
        vStreamWorker.addEventListener('message', function (e) {
            processWorkerMessage(e);
        });
        aStreamWorker.addEventListener('message', function (e) {
            processWorkerMessage(e);
        });
        vEncoderWorker.addEventListener('message', function (e) {
            processWorkerMessage(e);
        });
        aEncoderWorker.addEventListener('message', function (e) {
            processWorkerMessage(e);
        });
        muxerSenderWorker.addEventListener('message', function (e) {
            processWorkerMessage(e);
        });

        // Create a MediaStreamTrackProcessor, which exposes frames from the track
        // as a ReadableStream of VideoFrames.
        const vTrack = mediaStream.getVideoTracks()[0];
        const vProcessor = new MediaStreamTrackProcessor(vTrack);
        const vFrameStream = vProcessor.readable;

        const aTrack = mediaStream.getAudioTracks()[0];
        const aProcessor = new MediaStreamTrackProcessor(aTrack);
        const aFrameStream = aProcessor.readable;

        // Initialize encoders
        vEncoderWorker.postMessage({ type: "vencoderini", encoderConfig: videoEncoderConfig.encoderConfig, encoderMaxQueueSize: videoEncoderConfig.encoderMaxQueueSize, keyframeEvery: videoEncoderConfig.keyframeEvery });
        aEncoderWorker.postMessage({ type: "aencoderini", encoderConfig: audioEncoderConfig.encoderConfig, encoderMaxQueueSize: audioEncoderConfig.encoderMaxQueueSize });

        // Transport
        if (IS_LOCALHOST) {
            const fingerprint_filename = `${location.origin}/certs/certificate_fingerprint.hex`; 
            muxerSenderConfig.certificateHash = await getBinaryFile(fingerprint_filename)            
        }
        // Get url data
        muxerSenderConfig.urlHostPort = document.getElementById('wtServerUrl').value;
        
        //Get max Inflight requests & auth info                
        muxerSenderConfig.moqTracks["video"].namespace = document.getElementById('namespace').value.split("/");
        muxerSenderConfig.moqTracks["video"].name = MIgetTrackName(document.getElementById('trackName').value, false);
        muxerSenderConfig.moqTracks["video"].maxInFlightRequests = parseInt(document.getElementById('maxInflightVideoRequests').value);
        muxerSenderConfig.moqTracks["video"].authInfo = document.getElementById('authInfo').value;
        muxerSenderConfig.moqTracks["video"].moqMapping = document.getElementById('moqVideoQuicMapping').value;
        
        muxerSenderConfig.moqTracks["audio"].namespace = document.getElementById('namespace').value.split("/");
        muxerSenderConfig.moqTracks["audio"].name = MIgetTrackName(document.getElementById('trackName').value, true);
        muxerSenderConfig.moqTracks["audio"].maxInFlightRequests = parseInt(document.getElementById('maxInflightAudioRequests').value);
        muxerSenderConfig.moqTracks["audio"].authInfo = document.getElementById('authInfo').value;
        muxerSenderConfig.moqTracks["audio"].moqMapping = document.getElementById('moqAudioQuicMapping').value;

        // Initialize muxer - sender
        muxerSenderWorker.postMessage({ type: "muxersendini", muxerSenderConfig: muxerSenderConfig });

        // Transfer the readable stream to the worker.
        vStreamWorker.postMessage({ type: "stream", vStream: vFrameStream }, [vFrameStream]);
        aStreamWorker.postMessage({ type: "stream", aStream: aFrameStream }, [aFrameStream]);
    }

    // Add listeners from HTML
    window.addEventListener("load", (event) => {initUI();});
    document.getElementById('btnStart').addEventListener("click", (event) => {start();});
    document.getElementById('btnStop').addEventListener("click", (event) => {stop();});

    document.getElementById('videoSources').addEventListener("change", (event) => {onVideoSourceChanged(event.target.options[event.target.selectedIndex].value);});
    document.getElementById('audioSources').addEventListener("change", (event) => {onAudioSourceChanged(event.target.options[event.target.selectedIndex].value);});

    document.getElementById('videoEncodingOptions').addEventListener("change", (event) => {onVideoEncodingsSettingsChanged(event.target.options[event.target.selectedIndex].data);});

    document.getElementById('audioCodecOptions').addEventListener("change", (event) => {onAudioCodecChanged(event.target.options[event.target.selectedIndex].data);});
</script>